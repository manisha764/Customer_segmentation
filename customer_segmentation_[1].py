# -*- coding: utf-8 -*-
"""Customer Segmentation_[1]

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D-UifDwfL_M1O-9yZGhKgKj5Bd7yUaoN
"""

import pandas as pd

# Load the CSV file to inspect the data
file_path = '/content/Mall_Customers.csv'
data = pd.read_csv(file_path)

# Display the first few rows to understand the structure of the dataset
data.head()

# Assuming columns like 'Annual Income (k$)', 'Spending Score (1-100)', and 'Age' are present in the dataset
import numpy as np
# Number of Transactions: Assume customers with higher spending scores and incomes make more transactions
data['Number of Transactions'] = (data['Spending Score (1-100)'] * 0.5 + data['Annual Income (k$)'] * 0.1).astype(int)

# Average Transaction Value: Assume customers with higher income have higher transaction values
data['Average Transaction Value'] = data['Annual Income (k$)'] * np.random.uniform(0.5, 1.5, size=len(data))

# Transaction Frequency: Assume customers with higher spending scores and younger age make more frequent transactions
data['Transaction Frequency'] = (data['Spending Score (1-100)'] / data['Age']).clip(upper=10)  # Capping the frequency at 10

# Display the new dataset with the synthetic features
data[['Number of Transactions', 'Average Transaction Value', 'Transaction Frequency', 'Age', 'Annual Income (k$)', 'Spending Score (1-100)']].head()

# Elbow method to find the optimal number of clusters
inertia = []
K = range(1, 11)

for k in K:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(scaled_features)
    inertia.append(kmeans.inertia_)

# Plotting the elbow curve
plt.figure(figsize=(8, 5))
plt.plot(K, inertia, 'bo-', color='blue')
plt.title('Elbow Method for Optimal K')
plt.xlabel('Number of clusters (K)')
plt.ylabel('Inertia')
plt.grid(True)
plt.show()

# Step 2: Apply K-Means with the optimal number of clusters
optimal_k = 4  # Based on the elbow plot
kmeans = KMeans(n_clusters=optimal_k, random_state=42)
data['Cluster'] = kmeans.fit_predict(scaled_features)

# Step 3: Visualize the clusters
plt.figure(figsize=(8, 6))
sns.scatterplot(x='Annual Income (k$)', y='Spending Score (1-100)', hue='Cluster', data=data, palette='Set1', s=100)
plt.title('Customer Segments based on Annual Income and Spending Score')
plt.xlabel('Annual Income (k$)')
plt.ylabel('Spending Score (1-100)')
plt.legend(title='Cluster')
plt.show()

# Step 4: Visualize cluster centroids
centroids = scaler.inverse_transform(kmeans.cluster_centers_)

plt.scatter(centroids[:, 1], centroids[:, 2], color='black', s=300, label='Centroids')
sns.scatterplot(x='Annual Income (k$)', y='Spending Score (1-100)', hue='Cluster', data=data, palette='Set1', s=100)
plt.title('Cluster Centroids')
plt.xlabel('Annual Income (k$)')
plt.ylabel('Spending Score (1-100)')
plt.legend()
plt.show()

# Step 5: Analyze and summarize the clusters
cluster_summary = data.groupby('Cluster').agg({
    'Age': ['mean', 'min', 'max'],
    'Annual Income (k$)': ['mean', 'min', 'max'],
    'Spending Score (1-100)': ['mean', 'min', 'max'],
    'Number of Transactions': ['mean', 'min', 'max'],
    'Average Transaction Value': ['mean', 'min', 'max'],
    'Transaction Frequency': ['mean', 'min', 'max']
})

# Rename columns for better readability
cluster_summary.columns = [
    'Age Mean', 'Age Min', 'Age Max',
    'Income Mean', 'Income Min', 'Income Max',
    'Spending Score Mean', 'Spending Score Min', 'Spending Score Max',
    'Transactions Mean', 'Transactions Min', 'Transactions Max',
    'Transaction Value Mean', 'Transaction Value Min', 'Transaction Value Max',
    'Frequency Mean', 'Frequency Min', 'Frequency Max'
]

# Reset the index to make 'Cluster' a column
cluster_summary = cluster_summary.reset_index()

# Print the summary of each cluster
print(cluster_summary)

import matplotlib.pyplot as plt
import seaborn as sns

# Function to create bar plots for cluster analysis
def plot_cluster_summary(cluster_summary, feature, ylabel, title):
    # Extracting the mean, min, and max values for the given feature
    means = cluster_summary[f'{feature} Mean']
    mins = cluster_summary[f'{feature} Min']
    maxs = cluster_summary[f'{feature} Max']

    # Plotting the mean with error bars (min and max)
    plt.figure(figsize=(10, 6))
    sns.barplot(x='Cluster', y=means, data=cluster_summary, capsize=.2)
    plt.errorbar(cluster_summary['Cluster'], means, yerr=[means - mins, maxs - means], fmt='o', color='black', capsize=5)
    plt.title(title)
    plt.xlabel('Cluster')
    plt.ylabel(ylabel)
    plt.show()

# Plot for Age
plot_cluster_summary(cluster_summary, 'Age', 'Age', 'Age Summary by Cluster')

# Plot for Annual Income
plot_cluster_summary(cluster_summary, 'Income', 'Annual Income (k$)', 'Annual Income Summary by Cluster')

# Plot for Spending Score
plot_cluster_summary(cluster_summary, 'Spending Score', 'Spending Score (1-100)', 'Spending Score Summary by Cluster')

# Plot for Number of Transactions
plot_cluster_summary(cluster_summary, 'Transactions', 'Number of Transactions', 'Transactions Summary by Cluster')

# Plot for Average Transaction Value
plot_cluster_summary(cluster_summary, 'Transaction Value', 'Average Transaction Value', 'Average Transaction Value Summary by Cluster')

# Plot for Transaction Frequency
plot_cluster_summary(cluster_summary, 'Frequency', 'Transaction Frequency', 'Transaction Frequency Summary by Cluster')